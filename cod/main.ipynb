{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f4147fc8",
   "metadata": {
    "id": "f4147fc8"
   },
   "source": [
    "# Econometría Aplicada II\n",
    "## Tarea 1\n",
    "Importar librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0183c18b",
   "metadata": {
    "id": "0183c18b"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "\n",
    "# Don't crash\n",
    "from IPython import get_ipython\n",
    "\n",
    "# Clonar repo si estamos en colab\n",
    "if 'google.colab' in str(get_ipython()):\n",
    "    !git clone https://github.com/ArturoSbr/EmtrAp2-hw01\n",
    "    # !pip install scipy==1.7.3\n",
    "    #!pip install linearmodels\n",
    "    %cd EmtrAp2-hw01/cod\n",
    "\n",
    "# Libs\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "from statsmodels.api import OLS\n",
    "from linearmodels import PanelOLS\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f28d8dad",
   "metadata": {
    "id": "f28d8dad"
   },
   "source": [
    "Importar datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e10890",
   "metadata": {
    "id": "69e10890"
   },
   "outputs": [],
   "source": [
    "d1 = pd.read_csv('../dat/baseline.csv')\n",
    "d2 = pd.read_csv('../dat/endline.csv')\n",
    "d3 = pd.read_csv('../dat/completa.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b93ef3b8",
   "metadata": {
    "id": "b93ef3b8"
   },
   "source": [
    "### 1.1. Balance\n",
    "Tabla de balance por grupo de acuerdo a `T_nap`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a8a3d0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 381
    },
    "id": "14a8a3d0",
    "outputId": "54291182-c6c5-4c9c-b861-3ab60eef7f1d",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Seleccionar 10 variables basales\n",
    "X = ['time_in_office','age_','female_','education_','sleep_report','no_of_children_','act_inbed',\n",
    "     'an_12_number_of_awakenings','an_13_average_awakening_length','unemployed']\n",
    "\n",
    "# Inicializar lista\n",
    "d = []\n",
    "\n",
    "# Medias de variables basales\n",
    "for x in X:\n",
    "    # Grupos\n",
    "    b, a = d1.groupby('T_nap')[x].apply(np.array)\n",
    "    # t-test\n",
    "    test = stats.ttest_ind(a=a, b=b, equal_var=False, nan_policy='omit')\n",
    "    # Agregar a lista\n",
    "    d.append([x] + list(test))\n",
    "\n",
    "# A tabla\n",
    "t = pd.DataFrame(data=d, columns=['var','t','p']).sort_values('var')\n",
    "t['var'] = t['var'].str.replace('_',' ')\n",
    "t.round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e88ddf",
   "metadata": {
    "id": "94e88ddf",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# To latex\n",
    "# print(t.set_index('var').to_latex(float_format='%.3f', caption='Balance sobre 10 covariables'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6010a6d0",
   "metadata": {
    "id": "6010a6d0"
   },
   "source": [
    "Todos los p-values de las pruebas de diferencia de medias son mayores a 0.1. Esto significa que para toda variable independiente $X_j$, no podemos rechazar la hipótesis nula $\\mu_{X_j}^C = \\mu_{X_j}^T$. Las pruebas individuales sugieren que no existe ninguna diferencia entra las medias del grupo de control y el grupo de tratamiento.\n",
    "\n",
    "Para evaluar la significancia de manera conjunta, uso el siguiente modelo de probabilidad lineal:\n",
    "$$T_i = \\beta_0 + X_i^T \\beta + U_i$$\n",
    "donde $X_i^T$ contiene todos los controles evaluados en la prueba anterior.\n",
    "\n",
    "La prueba de hipótesis para determinar si al menos una de las variables indepentientes está relacionada con la asignación a tratamiento es:\n",
    "$$H_0: \\beta_1 = 0$$\n",
    "$$H_1: \\text{Al menos un coeficiente es distinto de cero}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf866f0f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bf866f0f",
    "outputId": "72b59a57-e1b2-4264-f5b2-17b70aed5960"
   },
   "outputs": [],
   "source": [
    "# T_nap en función de controles\n",
    "m = OLS(endog=d1['T_nap'], exog=d1[X].assign(const = 1)).fit()\n",
    "\n",
    "# Tabla de resumen\n",
    "print(m.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c364addf",
   "metadata": {
    "id": "c364addf"
   },
   "source": [
    "Al igual que en las diferencias de medias, todos los coeficientes estimados del modelo de probabilidad lineal tienen p-values menores a 0.1. Por ende, ninguno de las variables independientes tiene significancia individual para determinar la asignación a tratamiento.\n",
    "\n",
    "La prueba que nos interesa se ve reflejada en el estadístico $F$. La prueba de significancia conjunta tiene un p-value de 0.882. Es decir, no hay evidencia de que alguno de los coeficientes sea distinto de cero.\n",
    "\n",
    "Como conclusión, parece que el tratamiento sí fue asignado de manera aleatoria con base en los 10 controles que elegí.\n",
    "\n",
    "### 1.2. Efectos de tratamiento\n",
    "Efectos de tratamiento sobre la productividad de los trabajadores.\n",
    "\n",
    "#### a) Estimadores de Neyman"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d05b58a9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d05b58a9",
    "outputId": "42750cfe-6528-4ee6-e447-8f34ab6fc99b"
   },
   "outputs": [],
   "source": [
    "# Función para estimador de Neyman\n",
    "def neyman(frame, treatment_col, values_col):\n",
    "    # Arreglos C y T\n",
    "    m = frame[[treatment_col,values_col]].notna().all(axis=1)\n",
    "    a, b = frame[m].groupby(treatment_col)[values_col].apply(np.array)\n",
    "    # Diferencia de medias\n",
    "    tau = np.mean(b) - np.mean(a)\n",
    "    # Error estándar sobre-estimado\n",
    "    bse = np.sqrt(np.var(a, ddof=1) / len(a) + np.var(b, ddof=1) / len(b))\n",
    "    # t-stat\n",
    "    t = tau / bse\n",
    "    # p-value\n",
    "    p = 2 * (1 - stats.norm().cdf(np.abs(t)))\n",
    "    return [treatment_col, tau, bse, t, p]\n",
    "\n",
    "# Diferencia de Neyman\n",
    "prod_ney = neyman(d2, 'T_nap', 'productivity')\n",
    "print(f'Prueba de Neyman sobre productividad:\\n{prod_ney}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ed76558",
   "metadata": {
    "id": "2ed76558"
   },
   "source": [
    "#### b) Estimadores OLS sin controles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f69843a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9f69843a",
    "outputId": "37a2ccb8-9ebe-4fd4-ef71-49740fb66ad7"
   },
   "outputs": [],
   "source": [
    "m = OLS(endog=d2['productivity'], exog=d2.assign(const = 1)[['const','T_nap']], missing='drop')\n",
    "m = m.fit(cov_type='HC0')\n",
    "\n",
    "# Diferencia OLS sin X\n",
    "prod_ols = ['T_nap', m.params['T_nap'], m.bse['T_nap'], m.tvalues['T_nap'], m.pvalues['T_nap']]\n",
    "print(f'Estimación OLS sobre productividad:\\n{prod_ols}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "672981fe",
   "metadata": {
    "id": "672981fe"
   },
   "source": [
    "#### c) Estimadores con controles\n",
    "De acuerdo al paper, $X_i$ contiene `age_` en cuartiles, `female_` y la variable que indica si $i$ fue asignado a trabajar o a tomarse un break en vez de tomar una siesta.\n",
    "\n",
    "Como esta pregunta usa la base con promedios durante los 20 días de estudio, la variable que indica la actividad asignada cada día a los individuos del grupo de control no está disponible. Por ende, usaré el siguiente model:\n",
    "$$Y_i = \\beta_0 + \\sum_{q=1}^4I\\big[\\beta_q \\times Q(age_i)\\big] + \\beta_f fem_i$$\n",
    "donde $Q(age_i)$ asigna un cuartil a $i$ con base en su edad y $fem_i = 1$ si $i$ es mujer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29012c16",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "29012c16",
    "outputId": "33861108-2a09-49fe-fbeb-406cc13ef378"
   },
   "outputs": [],
   "source": [
    "# Edad a cuartiles y luego a dummies\n",
    "d2['age_q'] = pd.qcut(x=d2['age_'], q=4, labels=[f'q{i}' for i in range(1,5)])\n",
    "d2 = pd.get_dummies(data=d2, prefix='age_', prefix_sep='', columns=['age_q'], )\n",
    "\n",
    "# Tratamiento y controles\n",
    "X = ['T_nap','const','age_q2','age_q3','age_q4','female_']\n",
    "\n",
    "# Correr regresión\n",
    "m = OLS(endog=d2['productivity'], exog=d2.assign(const = 1)[X], missing='drop')\n",
    "m = m.fit(cov_type='HC0')\n",
    "\n",
    "# Regresión con controles\n",
    "prod_ctr = ['T_nap', m.params['T_nap'], m.bse['T_nap'], m.tvalues['T_nap'], m.pvalues['T_nap']]\n",
    "print(f'Estimación OLS+X sobre productividad:\\n{prod_ctr}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "taHtJSS3Y1xS",
   "metadata": {
    "id": "taHtJSS3Y1xS"
   },
   "source": [
    "#### d) Resultados a tabla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eyUKsklr_SAf",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 150
    },
    "id": "eyUKsklr_SAf",
    "outputId": "f270904e-5a1c-4fd4-ad18-66a0ab23f063"
   },
   "outputs": [],
   "source": [
    "# Concatenar resultados\n",
    "t = pd.DataFrame(data=[prod_ney, prod_ols, prod_ctr],\n",
    "                 columns=['Y','tau','se','t','p'],\n",
    "                 index=['Neyman','OLS simple','OLS controles'])\n",
    "\n",
    "# Tabla\n",
    "t = t.drop(columns=['Y'])\n",
    "t.round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba1c33e2",
   "metadata": {
    "id": "ba1c33e2"
   },
   "outputs": [],
   "source": [
    "# # To latex\n",
    "# print(t.to_latex(float_format='%.3f', caption='Estimaciones de ATE sobre productividad', label='t2_ates_prod'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "yhCJvUmyCRUy",
   "metadata": {
    "id": "yhCJvUmyCRUy"
   },
   "source": [
    "Los tres métodos indican que tomar una siesta tiene un efecto negativo sobre la productividad de los trabajadores. Sin embargo, todos los efectos estimados carecen de significancia. Es decir, el efecto promedio de tratamiento no es estadísticamente distinto de cero.\n",
    "\n",
    "Mi modelo preferido es el OLS con controles porque redujo el p-value del coeficiente asociado al tratamiento.\n",
    "\n",
    "#### e) Nuevas variables dependientes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "RNe2PpD_CifM",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 150
    },
    "id": "RNe2PpD_CifM",
    "outputId": "839da69e-a4f5-4688-f333-858b8bf646d9"
   },
   "outputs": [],
   "source": [
    "# Crear índice de habilidades cognitivas\n",
    "cog = ['corsi_measure','hf_measure','pvt_measure']\n",
    "d1['cog'] = d2[cog].apply(lambda x: (x - x.mean()) / x.std()).mean(axis=1)\n",
    "d2['cog'] = d2[cog].apply(lambda x: (x - x.mean()) / x.std()).mean(axis=1)\n",
    "\n",
    "# Nuevas variables dependientes\n",
    "Y = ['nap_time_mins','sleep_report','happy','cog','typing_time_hr']\n",
    "\n",
    "# Correr regresiones\n",
    "d = []\n",
    "for y in Y:\n",
    "    m = OLS(endog=d2[y], exog=d2.assign(const = 1)[X], missing='drop')\n",
    "    m = m.fit(cov_type='HC0')\n",
    "    d.append([m.params['T_nap'], m.tvalues['T_nap'], m.pvalues['T_nap']])\n",
    "\n",
    "# Resultados a tabla\n",
    "t = pd.DataFrame(data=d, columns=['tau','t','p'], index=Y)\n",
    "\n",
    "# Visualizar\n",
    "t.transpose().round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "953a0a9f",
   "metadata": {
    "id": "953a0a9f"
   },
   "outputs": [],
   "source": [
    "# print(t.transpose().to_latex(float_format='%.3f', caption='ATE sobre otras variables', label='t1.2_ates_other'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4Y2Chd2LDfmr",
   "metadata": {
    "id": "4Y2Chd2LDfmr"
   },
   "source": [
    "De acuerdo al modelo OLS con controles, el tratamiento:\n",
    "1. Aumenta el promedio de minutos dormidos durante la siesta de 0 a 11.7 minutos\n",
    "1. Aumenta el promedio de número de horas de sueño en 0.05 horas por día (pero no tiene significancia estadística)\n",
    "1. Aumenta el promedio de la calificación de felicidad reportada en 0.05 puntos (pero no tiene significancia estadística)\n",
    "1. Aumentar el índice promedio de desempeño cognitivo en 0.03 desviaciones estándar (pero no tiene significancia estadística)\n",
    "1. Reducir el promedio de horas trabajadas en 0.02 unidades diarias (pero no tiene significancia estadística)\n",
    "\n",
    "### 1.3. Fischer's Exact Test\n",
    "#### a) Probar si el tratamiento tiene efecto nulo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11061de9",
   "metadata": {
    "id": "11061de9"
   },
   "outputs": [],
   "source": [
    "# fet = stats.permutation_test(data=(d2.loc[d2['T_nap'].eq(1) & d2['productivity'].notna(), 'productivity'],\n",
    "#                                    d2.loc[d2['T_nap'].eq(0) & d2['productivity'].notna(), 'productivity']),\n",
    "#                              statistic=lambda x, y: np.mean(x) - np.mean(y),\n",
    "#                              n_resamples=1000,\n",
    "#                              random_state=42)\n",
    "\n",
    "# print('p-value:', round(fet.pvalue, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f58580fe",
   "metadata": {
    "id": "f58580fe"
   },
   "source": [
    "#### b) Conclusión\n",
    "Los p-values del efecto promedio estimado de tratamiento bajo Neyman y de OLS sin controles son 0.338 y 0.336 respectivamente. Con la falsificación de Fischer, el p-value es 0.308. Estos p-values son muy parecidos entre sí, por lo que podemos concluir con un alto grado de certeza que el efecto de las siestas sobre la productividad no es estadísticamente significativo.\n",
    "\n",
    "Cuando agregamos controles al modelo OLS, el p-value baja un poco (0.206), pero permance sin significancia estadística.\n",
    "\n",
    "En resumen, los cuatro métodos indican que las siestas no tienen un efecto estadísticamente significativo sobre la productividad de las personas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "YH7UHbqiyi38",
   "metadata": {
    "id": "YH7UHbqiyi38"
   },
   "source": [
    "### 1.4. Estratificación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "PTlD8fapF4a1",
   "metadata": {
    "id": "PTlD8fapF4a1"
   },
   "outputs": [],
   "source": [
    "# Crear casos con datos basales\n",
    "d1[['e','s']] = d1[['earnings','sleep_report']].apply(lambda x: (x >= x.median()).astype(int), axis=0)\n",
    "\n",
    "# Agregar casos a `d2`\n",
    "d2 = d2.merge(d1[['pid','e','s']], on='pid')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efc457e3",
   "metadata": {
    "id": "efc457e3"
   },
   "source": [
    "#### a) Número de observaciones asignadas a tratamiento y control en cada estrato"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1AEFkoVHCBeW",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 216
    },
    "id": "1AEFkoVHCBeW",
    "outputId": "8ed42d2d-df5c-44e4-bba9-0993756e0fd2"
   },
   "outputs": [],
   "source": [
    "t = d2.groupby(['e','s','T_nap']).size().reset_index(name='n')\n",
    "t = t.pivot(index=['e','s'], columns='T_nap', values='n')\n",
    "t.columns = ['ngC','ngT']\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5d59dae",
   "metadata": {
    "id": "a5d59dae"
   },
   "outputs": [],
   "source": [
    "# print(t.to_latex(caption='Observaciones por grupo', label='t1.4_strats'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "FuEEx1fuDDPd",
   "metadata": {
    "id": "FuEEx1fuDDPd"
   },
   "source": [
    "La tabla sí tiene los números que hubiera esperado ex-ante, pues los individuos asignados a tratamiento en cada grupo son prácticamente del mismo tamaño que el número de individuos asignado a control.\n",
    "\n",
    "#### b) Efectos por estrato y agregados usando Neyman\n",
    "Efectos por estrato"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Ff-NRUdj8mm2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 744
    },
    "id": "Ff-NRUdj8mm2",
    "outputId": "d738f6bf-0d70-4b09-ba65-04f7b707d2b7"
   },
   "outputs": [],
   "source": [
    "# Inicializar lista\n",
    "d = []\n",
    "\n",
    "# Efecto por esstrato a cada variable\n",
    "for y in Y:\n",
    "    for e, s in [(0,0),(0,1),(1,0),(1,1)]:\n",
    "        # Máscara\n",
    "        m = d2['e'].eq(e) & d2['s'].eq(s)\n",
    "        # ATE Neyman\n",
    "        d.append([e, s, m.sum(), m.sum() / len(d2), y] + neyman(d2[m], 'T_nap', y))\n",
    "\n",
    "# Resultados a tabla\n",
    "t = pd.DataFrame(data=d,\n",
    "                 columns=['e','s','ng','wg','depvar','indvar','tau','se','t','p'])\n",
    "t = t.set_index('depvar')\n",
    "\n",
    "\n",
    "# Visualizar resultados\n",
    "ates = [t[['e','s','tau','se','p']]]\n",
    "\n",
    "# Guardar resultados en lista para comparar más tarde\n",
    "ates[0].round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "M6uh5l0Q-7QT",
   "metadata": {
    "id": "M6uh5l0Q-7QT"
   },
   "source": [
    "Efectos agregados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "546696b9",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 744
    },
    "id": "546696b9",
    "outputId": "e809f891-ca10-44a7-a747-639fa5f6ea6d"
   },
   "outputs": [],
   "source": [
    "# t = t['tau'].multiply(t['wg']).groupby(t.index.get_level_values(0)).sum().to_frame(name='tau')\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1246b20c",
   "metadata": {
    "id": "1246b20c"
   },
   "outputs": [],
   "source": [
    "# To latex\n",
    "# print(t.to_latex(float_format='%.3f', caption='Efectos agregados', label='t1.4_ates'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lFW-SrlP-_LA",
   "metadata": {
    "id": "lFW-SrlP-_LA"
   },
   "source": [
    "#### c) Efectos estratificados con OLS\n",
    "$$Y_i = \\beta_0 + \\beta_1 T_i + \\beta_2 s_i + \\beta_3 s_i T_i + \\beta_4 e_i + \\beta_5 e_i T_i + \\beta_6 s_i e_i + \\beta_7 s_i e_i T_i + U_i$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc2db3cb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 744
    },
    "id": "fc2db3cb",
    "outputId": "27ce26bc-d880-4475-df1f-95f95da771ed"
   },
   "outputs": [],
   "source": [
    "# Inicializar lista\n",
    "d = []\n",
    "\n",
    "# Regresión para todas las depvar\n",
    "for y in Y:\n",
    "    # Modelo\n",
    "    formula = f'{y} ~ T_nap + s + I(s*T_nap) + e + I(e*T_nap) + I(e*s) + I(e*s*T_nap)'\n",
    "    m = OLS.from_formula(formula=formula, data=d2).fit(cov_type='HC0')\n",
    "    # Results table\n",
    "    res = pd.concat([m.params, m.bse, m.tvalues, m.pvalues], axis=1).assign(depvar = y)\n",
    "    d.append(res)\n",
    "\n",
    "# Todos los modelos en una tabla\n",
    "t = pd.concat(d, axis=0).reset_index()\n",
    "t.columns = ['beta','value','bse','t','p','depvar']\n",
    "\n",
    "# Coeficientes relevantes\n",
    "t = t[t['beta'].isin(['T_nap','I(e * T_nap)','I(s * T_nap)','I(e * s * T_nap)'])]\n",
    "\n",
    "# Aesthetics\n",
    "t = t.set_index('depvar')\n",
    "\n",
    "# Agregar a `ates`\n",
    "ates.append(t[['beta','value','bse','p']])\n",
    "\n",
    "# Visualizar\n",
    "ates[1].round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a-q1Pd3uGUhK",
   "metadata": {
    "id": "a-q1Pd3uGUhK"
   },
   "source": [
    "Resultados a tabla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "NtNs67qhGXSj",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 744
    },
    "id": "NtNs67qhGXSj",
    "outputId": "dc7bddc6-c74c-4b96-b1cf-bf682b24e1b1"
   },
   "outputs": [],
   "source": [
    "# Unir resultados\n",
    "t = pd.concat(ates, axis=1).reset_index()\n",
    "t = t.set_index(['depvar','e','s'])\n",
    "\n",
    "# Visualizar\n",
    "t.round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a2cbd9",
   "metadata": {
    "id": "b3a2cbd9"
   },
   "outputs": [],
   "source": [
    "# print(t.to_latex(float_format='%.3f', caption='Efecto de tratamiento por estrato', label='t1.4_ates_g'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "CH-S_ck8EgvX",
   "metadata": {
    "id": "CH-S_ck8EgvX"
   },
   "source": [
    "Los coeficientes estimados son idénticos. Por ejemplo, la diferencia de medias en `happy` para el estrato con ganancias debajo de la media y sueño arriba de la media es 0.043. Podemos obtener el mismo valor estimado si sumamos los coeficientes $T + s T = 0.043$.\n",
    "\n",
    "La única diferencia es en las pruebas de hipótesis. Mientras que con el estimador de Neyman solo tenemos que probar la hipótesis nula $H_0: \\hat{\\tau}_g = 0$, en el estimador con OLS tenemos que probar si la suma de los coeficientes que reconstruyen $\\hat{\\tau}_g$ es igual a cero usando un vector de restricción $l$.\n",
    "\n",
    "Los errores estándar de los estimadores por OLS serán distintos que por el método de Neyman, pero en general son parecidos entre sí. Esto lo podemos ver de manera intuitiva al ver los renglones que corresponden al grupo que gana y duerme por debajo de la mediana. Los $p$-values de ambos estimadores son parecidos.\n",
    "\n",
    "### 1.5. Atrición\n",
    "#### a) Reportar atrición"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eC-UEM2iMUbT",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 150
    },
    "id": "eC-UEM2iMUbT",
    "outputId": "0e43958c-b71e-492c-f4c0-897aaafaaa48",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "t = d2.groupby('T_nap')['drop_indicator'].agg(['size','sum'])\n",
    "t['pct_int'] = t['sum'].div(t['size']) * 100\n",
    "t['pct_ext'] = t['sum'].div(t['size'].sum()) * 100\n",
    "t.round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adcd443c",
   "metadata": {
    "id": "adcd443c"
   },
   "outputs": [],
   "source": [
    "# print(t.to_latex(float_format='%.2f', caption='Atrición', label='t1.5_attritors'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "LLZVrrPwMhDb",
   "metadata": {
    "id": "LLZVrrPwMhDb"
   },
   "source": [
    "#### b) Nuevo balance\n",
    "Validez interna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "qUvzp87XNUcK",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 414
    },
    "id": "qUvzp87XNUcK",
    "outputId": "7b8809fc-39b6-42fb-f06c-472f7e4f86b1"
   },
   "outputs": [],
   "source": [
    "# Variables dependientes\n",
    "X = ['time_in_office','age_','female_','education_','sleep_report','no_of_children_','act_inbed',\n",
    "     'an_12_number_of_awakenings','an_13_average_awakening_length','unemployed']\n",
    "\n",
    "# Tabla de balance\n",
    "d = []\n",
    "for x in X:\n",
    "    b, a = d1[d1['drop_indicator'].eq(0)].groupby('T_nap')[x].apply(np.array)\n",
    "    test = stats.ttest_ind(a=a, b=b, equal_var=False, nan_policy='omit')\n",
    "    d.append([x] + list(test))\n",
    "\n",
    "# A tabla\n",
    "t = pd.DataFrame(data=d, columns=['variable','t','p']).set_index('variable')\n",
    "t.round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ed1355",
   "metadata": {
    "id": "d9ed1355"
   },
   "outputs": [],
   "source": [
    "# print(t.to_latex(float_format='%.3f', caption='Validez interna', label='t1.5_internal'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "SZErnC7pMCNj",
   "metadata": {
    "id": "SZErnC7pMCNj"
   },
   "source": [
    "Prueba conjunta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0759b7d1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0759b7d1",
    "outputId": "254f3788-3b5c-422f-c70a-56b2d74d9d0b"
   },
   "outputs": [],
   "source": [
    "m = OLS(endog=d2.loc[d2['drop_indicator'].eq(0), 'T_nap'],\n",
    "        exog=d2.loc[d2['drop_indicator'].eq(0), X].assign(const = 1),\n",
    "        missing='drop').fit(cov_type='HC0')\n",
    "print(f'p-value de significancia conjunta: {round(m.f_pvalue.item(), 3)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "WwOgaRHULR4V",
   "metadata": {
    "id": "WwOgaRHULR4V"
   },
   "source": [
    "Sí tenemos un problema de validez interna porque después de la atrición los niveles promedio de educación y número de hijos son estadísticamente distintos entre los grupos de tratamiento y control. Si hacemos un $F$-test de significancia conjunta, rechazamos la hipótesis de que todos los coeficientes sean simultáneamente iguales a cero porque el $p$-value de la prueba es 0.095.\n",
    "\n",
    "Validez externa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "SsPmAQNoSCPm",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 414
    },
    "id": "SsPmAQNoSCPm",
    "outputId": "f7157fc6-2e90-454a-fa8f-b4f0db2e39a3"
   },
   "outputs": [],
   "source": [
    "# Probar si diferencia es significativa\n",
    "d = []\n",
    "for x in X:\n",
    "    b, a = d1.groupby('drop_indicator')[x].apply(np.array)\n",
    "    test = stats.ttest_ind(a=a, b=b, equal_var=False, nan_policy='omit')\n",
    "    d.append([x] + list(test))\n",
    "\n",
    "# Resultados a tabla\n",
    "t = pd.DataFrame(data=d, columns=['variable','t','p']).set_index('variable')\n",
    "t.round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a2b220",
   "metadata": {
    "id": "65a2b220"
   },
   "outputs": [],
   "source": [
    "# print(t.to_latex(float_format='%.3f', caption='Validez externa', label='t1.5_external'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93Z_5pV_NST5",
   "metadata": {
    "id": "93Z_5pV_NST5"
   },
   "source": [
    "Prueba de significancia conjunta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1IohJRGdNUdK",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1IohJRGdNUdK",
    "outputId": "c9cbf5b3-a0f9-435b-886c-4d4b2db83f50"
   },
   "outputs": [],
   "source": [
    "m = OLS(endog=d1['drop_indicator'], exog=d1[X].assign(const = 1)).fit(cov_type='HC0')\n",
    "round(m.f_pvalue.item(0), 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "IEM0OS9kUMBk",
   "metadata": {
    "id": "IEM0OS9kUMBk"
   },
   "source": [
    "La atrición parece no haber afectado la validez externa de la muestra. Usando las pruebas individuales, la atrición tiene un $p$-value bajo para el número de hijos y mujeres. Sin embargo, ambas variables carecen de significancia estadística al 10%. Asimismo, la prueba conjunta resulta en un $p$-value muy cercano a cero, por lo que no podemos rechazar que todos los coeficientes sean distintos de cero simultáneamente. Es decir, parece que no existe un problema de validez externa.\n",
    "\n",
    "#### c) Conclusión\n",
    "La atrición fue sistemática entre el grupo de tratamiento y de control. Es decir, parece que el nivel de educación y el número de hijos determinan si alguien abandona o no el experimento. Esto nos lleva a un problema de validez interna porque los grupos de tratamiento y control después de la atrición no están balanceados.\n",
    "\n",
    "Sin embargo, parece que la atrición no afectó la validez externa de la muestra, pues parece que las personas que abandonaron el estudio no afectaron las distribuciones de las variables de control. Ninguna de las 10 variables muestra una diferencia significativa antes y después de la atrición.\n",
    "\n",
    "### 5. Lee Bounds\n",
    "#### a) Perfiles\n",
    "- Always Respondents: $S_i$ = 1 sin importar $T_i$\n",
    "- Never Respondents: $S_i$ = 0 sin importar $T_i$\n",
    "- Selective Respondents: $T_i = 0 \\implies S_i = 0$, $T_i = 1 \\implies S_i = 1$\n",
    "- Counter-Selective Respondents: $T_i = 0 \\implies S_i = 1$, $T_i = 1 \\implies S_i = 0$\n",
    "\n",
    "El supuesto de monotonicidad es que no existe alguno de los dos grupos de respuesta selectiva. En el contexto de este experimento, tiene sentido asumir que los Counter-Selective Respondents no existen porque el tratamiento es algo *bueno*. Es decir, si a alguien le toca tomar una siesta durante sus horas de trabajo, es razonable pensar que el tratamiento es algo deseable y por ende no incentivaría a los individuos a abandonar el experimento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "WY67mJbVUUje",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 150
    },
    "id": "WY67mJbVUUje",
    "outputId": "2eee071c-31e5-4b9d-9a1d-e001939923d2"
   },
   "outputs": [],
   "source": [
    "# Columna S_i\n",
    "d2['S'] = 1 - d2['drop_indicator']\n",
    "\n",
    "# Casos\n",
    "t = d2.groupby(['T_nap','S']).size()\n",
    "t.unstack().transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eh7_SNr7PFu8",
   "metadata": {
    "id": "eh7_SNr7PFu8"
   },
   "source": [
    "Calcular probabilidades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "003ebdea",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "003ebdea",
    "outputId": "c8cb6d45-a22c-4b2e-a32c-6056ea1c9d8d"
   },
   "outputs": [],
   "source": [
    "# P(AR|T=0)\n",
    "par = 128 / (81 + 128)\n",
    "\n",
    "# P(SR|T=1)\n",
    "psr = 182 / (182 + 23) - par\n",
    "\n",
    "# Probabilidades\n",
    "print(f'P(AR) = {par}', f'P(SR) = {psr}', f'P(NR) = {1 - (par + psr)}', sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "effdd023",
   "metadata": {
    "id": "effdd023"
   },
   "source": [
    "\n",
    "\n",
    "#### b) Lee Bounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "684ccda0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "684ccda0",
    "outputId": "07f05d98-bcfd-4927-c135-85f8407cbf7d"
   },
   "outputs": [],
   "source": [
    "# P(AR|S=1)\n",
    "# par_s = par / d2['S'].mean()\n",
    "par_s = par / (par + psr)\n",
    "\n",
    "# Arreglos trat-cont dado S=1\n",
    "a, b = d2[d2['S'].eq(1)].groupby('T_nap')['productivity'].apply(np.array)\n",
    "\n",
    "# Lower bound\n",
    "lb = b[b <= np.quantile(b, par_s)].mean() - a.mean()\n",
    "\n",
    "# Upper bound\n",
    "ub = b[b >= np.quantile(b, 1 - par_s)].mean() - a.mean()\n",
    "\n",
    "# Bounds\n",
    "print(f'El ATE de los AR está en [{lb, ub}]')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "532fff46",
   "metadata": {
    "id": "532fff46"
   },
   "source": [
    "#### c) Comparación\n",
    "Los resultados de la pregunta 2 no tienen por qué estar centrados en los Lee Bounds porque estiman el efecto para toda la población, mientras que el intervalo de esta pregunta acota el efecto de tratamiento para los Always Respondents.\n",
    "\n",
    "Lo único que sí podemos ver es que el ATE observado en la muestra completa es mayor al ATE de los Always Respondents."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8b1cbaf",
   "metadata": {
    "id": "f8b1cbaf"
   },
   "source": [
    "## 2. Matching\n",
    "Favor de consultar arvhivo `matching.R`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6453708",
   "metadata": {},
   "source": [
    "## 3. Difference in Differences\n",
    "### 3.1. Tabla 2x2\n",
    "Uso baseline como `t0` y endline como `t1` ignorando atrición."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e899c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pegar d1 & d2\n",
    "t = pd.concat([d1[['pid','T_nap','productivity']].assign(t = 0),\n",
    "               d2[['pid','T_nap','productivity']].assign(t = 1)],\n",
    "              axis=0)\n",
    "\n",
    "# Agrupar\n",
    "t = t.groupby(['T_nap','t'])['productivity'].mean().reset_index(name='mean')\n",
    "\n",
    "# Formato 2x2\n",
    "t = t.pivot(index='t', columns='T_nap')\n",
    "\n",
    "# Visualizar\n",
    "t.round(2)\n",
    "\n",
    "# To latex\n",
    "# print(t.to_latex(float_format='%.2f', caption='Matriz de comparación', label='t3_2x2'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3c4fe40",
   "metadata": {},
   "source": [
    "Con los periodos $t \\in \\{0, 1\\}$, el resultado anterior se puede estimando el coeficiente $\\beta_3$ del modelo\n",
    "$$prod_{it} = \\beta_0 + \\beta_1 T_i + \\beta_2 t + \\beta_3 t \\times T_i + U_i$$\n",
    "\n",
    "De acuerdo a la tabla, el ATE es:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "853da486",
   "metadata": {},
   "outputs": [],
   "source": [
    "(t.iloc[1, 1] - t.iloc[0, 1]) - (t.iloc[1, 0] - t.iloc[0, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a317c7e",
   "metadata": {},
   "source": [
    "### 3.2. 2x2\n",
    "De acuerdo al paper, todos los individuos permanencieron en control durante los primeros ocho días del estudio y el experimento comenzó en el noveno día. Por ende, consideraré que el periodo $t = 0$ son las medias agrupadas de las observaciones de los primeros ocho días, y que el periodo $t = 1$ son las medias agrupadas de las observaciones de los días restantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df4018c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Asignar tiempo binario\n",
    "d3['t'] = np.where(d3['day_in_study'] <= 8, 0, 1)\n",
    "\n",
    "# Agrupar por i, t para tener dos observationes por individuo\n",
    "t = d3.groupby(['pid','t'])[['productivity','T_nap','age_','female_']].mean().reset_index()\n",
    "\n",
    "# Verificar si todos tienen dos periodos observados\n",
    "t.groupby('pid').size().agg(['min','max'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bdf2150",
   "metadata": {},
   "source": [
    "Verificar que nadie tenga NANs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b3166ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "t.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quitar NaNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c98a7a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quitar a pid que tiene NAN en productivity\n",
    "t = t[t['pid'] != t.loc[t['productivity'].isna(), 'pid'].item()]\n",
    "\n",
    "# Conteo\n",
    "print(f\"Cada uno de los {t['pid'].nunique()} individuos tiene dos periodos ({len(t)} observaciones en total))\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01953557",
   "metadata": {},
   "source": [
    "Usando el método recién mencionado, conservo a más individuos que con las bases baseline y endline. Con esta nueva base, la tabla $2 \\times 2$ queda así:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47360ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agrupar\n",
    "t2 = t.groupby(['T_nap','t'])['productivity'].mean().reset_index(name='mean')\n",
    "\n",
    "# Formato 2x2\n",
    "t2 = t2.pivot(index='t', columns='T_nap')\n",
    "\n",
    "# Visualizar\n",
    "t2.round(2)\n",
    "\n",
    "# To latex\n",
    "# print(t2.to_latex(float_format='%.2f', caption='Matriz de comparación (Versión 2)', label='t3_2x2_v2'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92ff9386",
   "metadata": {},
   "source": [
    "Debido a que la tabla es un poco distinta, el TOT es un poco distinto por la naturaleza de la población. De acuerdo a esta tabla, el TOT es:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57b78d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "(t2.iloc[1, 1] - t2.iloc[0, 1]) - (t2.iloc[1, 0] - t2.iloc[0, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8cfb5bf",
   "metadata": {},
   "source": [
    "Regresión sin controles con el modelo\n",
    "$$prod_{it} = \\beta_0 + \\beta_1 T_i + \\beta_2 t + \\beta_3 t \\times T_i + U_i$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c573d8aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regresión con controles\n",
    "m = OLS.from_formula('productivity ~ T_nap + t + I(t*T_nap)', t).fit()\n",
    "m.params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f17028d",
   "metadata": {},
   "source": [
    "Regresión con controles con el modelo\n",
    "$$prod_{it} = \\beta_0 + \\beta_1 T_i + \\beta_2 t + \\beta_3 t \\times T_i + age_i + female_i + U_i$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a10793c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regresión con controles\n",
    "m = OLS.from_formula('productivity ~ T_nap + t + I(t*T_nap) + age_ + female_', t).fit()\n",
    "m.params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf7ab763",
   "metadata": {},
   "source": [
    "Para ambas regresiones debería usar errores clusterizados porque las variables observadas para un mismo individuo no son independientes ni idénticamente distribuidas entre ambos periodos de tiempo. La segunda instancia de cualquier variable es argumentablemente dependiente del su valor en el periodo de tiempo anterior.\n",
    "\n",
    "### 3.3. Comparación\n",
    "Los valores estimados del ATT en la productividad usando Matching varían entre $-953.26$ y $-814.67$. Los ATTs\n",
    "usando cualquier estimador de Diferencia en Diferencias (DiD por sus siglas en inglés) resulta en valores positivos (entre $79.75$ y $87.56$).\n",
    "\n",
    "En lo personal, confío más en el estimador de DiD, pues Matching funciona cuando puedes emparejar a la población con base en todas las covariables que podrían sesgar la diferencia de medias. En el caso de este estudio, hay muchos ejemplos de covariables no observables que podrían sesgar el efecto de las siestas sobre la productividad de aquellos individuos que recibieron el tratamiento. Por ejemplo, habilidad natural, conocimiento de computadoras, interés en el trabajo, etc. Como estas variables no son observables, no podemos medir si existe un desbalance en estos controles al emparejar por las variables que sí son observables. En caso de que Matching produzca desbalances en estas variables, el ATT estimado estará sesgado a pesar de estar balanceado en las variables por las cuales emparejamos a la población.\n",
    "\n",
    "Al tomar la diferencia entre los periodos primero y segundo dentro de cada grupo (tratamiento o control), el estimador DiD es capaz de eliminar el sesgo por cualquier variable no observada siempre y cuando permanezca constante en el tiempo. Como el estudio duró 28 días, cualquier variación en el tiempo de las variables no observables sería negligible porque seguramente no cambiarían mucho dentro de un periodo de tiempo tan corto. Por ende, considero que los ATTs por el método de DiD es más confiable que el ATT usando Matching.\n",
    "\n",
    "### 3.4. Figuras\n",
    "#### 3.4.1. Series de tiempo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a36d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear grupos\n",
    "d3['group'] = np.where(\n",
    "    d3['T_nap'].eq(0),\n",
    "    'No naps',\n",
    "    np.where(\n",
    "        d3['T_nap'].eq(1) & d3['treatment_group'].eq(0),\n",
    "        'Nap only',\n",
    "        np.where(\n",
    "            d3['T_nap'].eq(1) & d3['treatment_group'].eq(1),\n",
    "            'Nap and encouragement',\n",
    "            'Nap and incentives'\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "# Minutos por grupo\n",
    "t = d3.groupby(['group','day_in_study'])[['nap_time_mins']].mean().fillna(0).reset_index()\n",
    "\n",
    "# Plot\n",
    "for g in t['group'].unique():\n",
    "    # Mask\n",
    "    m = t['group'].eq(g)\n",
    "\n",
    "    # Line plot\n",
    "    plt.plot(t.loc[m, 'day_in_study'], t.loc[m, 'nap_time_mins'], label=g)\n",
    "\n",
    "plt.axvline(8.5, color='black', ls='--')\n",
    "\n",
    "# Aesthetics\n",
    "plt.legend()\n",
    "plt.xlim(2, 27)\n",
    "plt.ylim(0, 17)\n",
    "plt.xlabel('Day in Study')\n",
    "plt.ylabel('Nap Duration (Minutes)')\n",
    "plt.title('(d) Nap Sleep')\n",
    "\n",
    "# Save\n",
    "if 'google.colab' not in str(get_ipython()):\n",
    "    plt.savefig('../fig/f341-nap-mins.png', dpi=200, bbox_inches='tight')\n",
    "\n",
    "# Show\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4.2 Promedios por rango de días\n",
    "La gráfica que se intentó replicar necesitaba la variable Break Time para comparar a los individuos de tratamiento de aquellos que fueron asignados a tomar un descanso durante el timepo de siesta. Como esta variable no está disponible en ninguna de las bases, grafiqué los efectos de tratamiento tomando como grupo de referencia a los que no tomaron una siesta (trabajadores que se tomaron un descanso o que trabajaron durante las siestas)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declarar grupos de días\n",
    "d3['groupDay'] = np.where(\n",
    "    d3['day_in_study'].le(8) | d3['day_in_study'].eq(28),\n",
    "    'Bye',\n",
    "    np.where(\n",
    "        d3['day_in_study'].between(9, 12),\n",
    "        '09-12',\n",
    "        np.where(\n",
    "            d3['day_in_study'].between(13, 15),\n",
    "            '13-15',\n",
    "            np.where(\n",
    "                d3['day_in_study'].between(16, 18),\n",
    "                '16-18',\n",
    "                np.where(\n",
    "                    d3['day_in_study'].between(19, 21),\n",
    "                    '19-21',\n",
    "                    np.where(\n",
    "                        d3['day_in_study'].between(22, 24),\n",
    "                        '22-24',\n",
    "                        '25-27'\n",
    "                    )\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "# Declarar variables promedio en baseline\n",
    "\n",
    "\n",
    "# Convertir typing_time_hr a mins\n",
    "d3['typing_time_mins'] = d3['typing_time_hr'] * 60\n",
    "\n",
    "# Agrupar\n",
    "m = d3['day_in_study'].between(9, 27)\n",
    "t = d3[m].groupby(['groupDay','T_nap'])[['earnings','typing_time_mins','productivity']].agg(['mean','std','size'])\n",
    "\n",
    "# Plots\n",
    "fig, axes = plt.subplots(nrows=3, ncols=1)#, sharex=True)\n",
    "fig.set_figheight(10)\n",
    "fig.subplots_adjust(hspace=.5)\n",
    "\n",
    "# Titles by case\n",
    "ttls = {'earnings':'Earnings', 'typing_time_mins':'Minutes typing', 'productivity':'Productivity'}\n",
    "\n",
    "for i, y in enumerate(['earnings','typing_time_mins','productivity']):\n",
    "    # Get axis\n",
    "    ax = axes.flatten()[i]\n",
    "\n",
    "    # To frame\n",
    "    d = t[y].reset_index()\n",
    "\n",
    "    # Get tau\n",
    "    d['tau'] = d['mean'] - d.groupby('groupDay')['mean'].shift()\n",
    "\n",
    "    # Get std\n",
    "    d['s'] = d['std'].div(d['size'])\n",
    "    d['s'] = np.sqrt(d['s'] + d.groupby('groupDay')['s'].shift())\n",
    "\n",
    "    # Keep second row per group\n",
    "    d = d.loc[d['T_nap'].eq(1), ['groupDay','tau','s']]\n",
    "\n",
    "    # Plot\n",
    "    ax.errorbar(\n",
    "        x=d['groupDay'], y=d['tau'], yerr=d['s'] * 1.96,\n",
    "        ls='none', marker='^', elinewidth=1, capsize=4\n",
    "    )\n",
    "\n",
    "    # Plot aesthetics\n",
    "    ax.axhline(0, color='black', lw=1)\n",
    "    ax.set_xlabel('Day in Study')\n",
    "    ax.set_ylabel(ttls[y])\n",
    "    ax.set_title(ttls[y])\n",
    "    \n",
    "    # Save figure\n",
    "    if 'google.colab' not in str(get_ipython()):\n",
    "        plt.savefig('../fig/f341-Ys.png', dpi=200, bbox_inches='tight')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.5. Tendencias paralelas\n",
    "\n",
    "Tras eliminar las observaciones que abandonaron el experimento, uso evalúo las tendencias durante los ocho días previos al inicio del tratamiento usando el modelo:\n",
    "$$Y_{it} = \\beta_0 + \\beta_1 T_i + \\sum_{s < 0} \\Big[ \\delta_s DS_t + \\tau_s DS_t \\Big] + U_{it}$$\n",
    "\n",
    "Mis hipótesis son:\n",
    "\n",
    "$H_0: \\tau_t = 0 \\text{ } \\forall \\text{ } t \\in \\{-7, -6, -1\\}$\n",
    "\n",
    "$H_1:$ Cualquier otro caso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recentrar en t = 8\n",
    "d3['t'] = d3['day_in_study'] - 8\n",
    "\n",
    "# Copiar d3\n",
    "cols = ['pid','t','T_nap','productivity']\n",
    "d = d3[cols].copy()\n",
    "\n",
    "# Conservar a pid's SIN drop_indicator\n",
    "d = d[d['pid'].isin(d2.loc[d2['drop_indicator'].eq(0), 'pid'].values)].reset_index(drop=True)\n",
    "\n",
    "# Datos previos al tratamiento\n",
    "t = d[d['t'] <= 0]\n",
    "t = t.groupby(['T_nap','t'])['productivity'].mean().reset_index(name='y')\n",
    "\n",
    "# Plot\n",
    "for T in [0, 1]:\n",
    "    label = {0:'Control',1:'Tratamiento'}[T]\n",
    "    plt.plot(t.loc[t['T_nap'].eq(T), 't'], t.loc[t['T_nap'].eq(T), 'y'], label=label)\n",
    "\n",
    "# Aesthetics\n",
    "plt.title('Tendencias antes del tratamiento')\n",
    "plt.xlabel('Días desde el tratamiento')\n",
    "plt.ylabel('Productividad')\n",
    "plt.legend()\n",
    "try:\n",
    "    plt.savefig('../fig/f35-parallel.png', dpi=200, bbox_inches='tight')\n",
    "except:\n",
    "    True\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparar datos para PanelOLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear copia de datos\n",
    "t = d[d['t'] <= 0].copy()\n",
    "\n",
    "# Crear dummies por periodo\n",
    "s = pd.get_dummies(t[['t']], columns=['t'], drop_first=False, prefix_sep='')\n",
    "\n",
    "# Declarar a t0 como el periodo de referencia\n",
    "s.drop(columns=['t0'], inplace=True)\n",
    "\n",
    "# Interacciones tiempoXtratamiento\n",
    "s2 = s.multiply(t['T_nap'], axis=0)\n",
    "s2.columns = [f'{col}*T_nap' for col in s2.columns]\n",
    "\n",
    "# Pegar a datos\n",
    "t = pd.concat([t, s, s2], axis=1)\n",
    "\n",
    "# Asignar constante\n",
    "t['const'] = 1\n",
    "\n",
    "# PanelOLS Index\n",
    "t.set_index(['pid','t'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ajustar modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajustar modelo\n",
    "m = PanelOLS(t['productivity'], t.loc[:, 't-7':'const'])\n",
    "m = m.fit(cov_type='clustered', cluster_entity=True)\n",
    "\n",
    "# Resumen\n",
    "print(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparar contra modelo restringido (modelo que asume que las pendientes son idénticas)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Restricted model\n",
    "mR = PanelOLS(t['productivity'], t.loc[:, 't-7':'t-1'].assign(const = 1))\n",
    "mR = mR.fit(cov_type='clustered', cluster_entity=True)\n",
    "\n",
    "# F-test\n",
    "Fstat = ((mR.resid_ss - m.resid_ss) / (m.df_model - mR.df_model)) / (mR.resid_ss / (mR.nobs - mR.df_model))\n",
    "p = 1 - stats.f(dfn=7, dfd=m.df_resid).cdf(Fstat)\n",
    "print(f'F-stat = {Fstat}')\n",
    "print(f'p-value = {round(p, 3)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.6 Matching y DiD\n",
    "Rellené la serie para cada `pid` usando:\n",
    "1. Las medias de los datos basales para missings en los primeros 8 días\n",
    "2. La media móvil de los últimos 5 días para missings en los días 9 y adelante\n",
    "\n",
    "Con series llena para todo `pid`, podemos hacer un match entre tratamiento y control usando controles vistos en Baseline. Luego, podemos usar los pesos para hacer el DiD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep copy of non-dropped pids\n",
    "s = d2.loc[d2['drop_indicator'].eq(0), 'pid'].values\n",
    "d = d3[d3['pid'].isin(s)].copy()\n",
    "\n",
    "# Define cog from baseline\n",
    "m = d1[cog].mean()\n",
    "s = d1[cog].std()\n",
    "for x in cog:\n",
    "    d[x] = (d[x] - m[x]) / s[x]\n",
    "d['cog'] = d[cog].mean(axis=1)\n",
    "\n",
    "# Columns to store in lean data\n",
    "cols = [\n",
    "    'pid','day_in_study','T_nap',                                                   # i-level\n",
    "    'productivity','nap_time_mins','sleep_report','happy','cog','typing_time_hr'    # Targets\n",
    "]\n",
    "\n",
    "# Lean data\n",
    "d = d[cols]\n",
    "d = d.sort_values(['pid','day_in_study'])\n",
    "\n",
    "# Columns to fill in by pid\n",
    "cols = ['pid','productivity','nap_time_mins','sleep_report','happy','cog','typing_time_hr']\n",
    "\n",
    "# Completar datos basales con medias basales\n",
    "s = d1[cols].fillna(0)\n",
    "s.columns = [col + '_B' for col in s.columns]\n",
    "d = d.merge(s, left_on='pid', right_on='pid_B', how='inner')\n",
    "for y in cols[1:]:\n",
    "    d[y] = np.where(d['day_in_study'].le(8) & d[y].isna(), d[y + '_B'], d[y])\n",
    "\n",
    "# Completar datos experimentales con moving averages\n",
    "s = d.rolling(window=7, min_periods=0, on='pid', center=False)[cols[1:]].mean()\n",
    "s.columns = [col + '_ma' for col in s.columns]\n",
    "d = d.merge(s, left_on='pid', right_on='pid_ma', how='inner')\n",
    "for y in cols[1:]:\n",
    "    d[y] = np.where(d['day_in_study'].ge(9) & d[y].isna(), d[y + '_ma'], d[y])\n",
    "\n",
    "# Eliminar columnas para rellenar\n",
    "d = d.drop(columns=[col+'_B' for col in cols] + [col+'_ma' for col in cols])\n",
    "\n",
    "# People who are still missing data\n",
    "s = d[cols].isna().groupby(d['pid']).sum()\n",
    "\n",
    "# Begone foul beasts\n",
    "s = s[s.sum(axis=1) > 0].index.values\n",
    "d = d[~d['pid'].isin(s)].reset_index(drop=True)\n",
    "\n",
    "# Exportar para match en R\n",
    "d.to_csv('../dat/unmatched.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Traer relación de matchit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matches and weights\n",
    "s = pd.read_csv('../dat/matched.csv')\n",
    "\n",
    "# Merge\n",
    "d = d.merge(s, on='pid', how='inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ver tendencias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear copia\n",
    "s = d.copy()\n",
    "\n",
    "# Recentrar en t = 8\n",
    "s['t'] = s['day_in_study'] - 8\n",
    "\n",
    "# Copiar d3\n",
    "s = s[['pid','t','T_nap','productivity']]\n",
    "\n",
    "# Datos previos al tratamiento\n",
    "t = s[s['t'] <= 0]\n",
    "t = t.groupby(['T_nap','t'])['productivity'].mean().reset_index(name='y')\n",
    "\n",
    "# Plot\n",
    "for T in [0, 1]:\n",
    "    label = {0:'Control',1:'Tratamiento'}[T]\n",
    "    plt.plot(t.loc[t['T_nap'].eq(T), 't'], t.loc[t['T_nap'].eq(T), 'y'], label=label)\n",
    "\n",
    "# Aesthetics\n",
    "plt.title('Tendencias antes del tratamiento')\n",
    "plt.xlabel('Días desde el tratamiento')\n",
    "plt.ylabel('Productividad')\n",
    "plt.legend()\n",
    "try:\n",
    "    plt.savefig('../fig/f36-parallel.png', dpi=200, bbox_inches='tight')\n",
    "except:\n",
    "    True\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ATT por día"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Centrar tiempo y crear indicador binario\n",
    "d['t'] = d['day_in_study'] - 8\n",
    "d['post'] = np.where(d['day_in_study'] >= 9, 1, 0)\n",
    "\n",
    "# Crear copia de datos\n",
    "t = d.copy()\n",
    "\n",
    "# Crear dummies por periodo\n",
    "s = pd.get_dummies(t[['t']], columns=['t'], drop_first=False, prefix_sep='')\n",
    "\n",
    "# Eliminar t0\n",
    "s.drop(columns=['t0'], inplace=True)\n",
    "\n",
    "# Interacciones tiempoXtratamiento\n",
    "s2 = s.multiply(t['T_nap'], axis=0)\n",
    "s2.columns = [f'{col}*T_nap' for col in s2.columns]\n",
    "\n",
    "# Pegar a datos\n",
    "t = pd.concat([t, s, s2], axis=1)\n",
    "\n",
    "# Asignar constante\n",
    "t['const'] = 1\n",
    "\n",
    "# PanelOLS Index\n",
    "t.set_index(['pid','t'], inplace=True)\n",
    "\n",
    "# Covariates\n",
    "X = [\n",
    "    'const','T_nap','t-7','t-6','t-5','t-4','t-3','t-2','t-1','t1','t2','t3','t4','t5','t6','t7','t8','t9',\n",
    "    't10','t11','t12','t13','t14','t15','t16','t17','t18','t19','t20','t-7*T_nap','t-6*T_nap','t-5*T_nap',\n",
    "    't-4*T_nap','t-3*T_nap','t-2*T_nap','t-1*T_nap','t1*T_nap','t2*T_nap','t3*T_nap','t4*T_nap','t5*T_nap',\n",
    "    't6*T_nap','t7*T_nap','t8*T_nap','t9*T_nap','t10*T_nap','t11*T_nap','t12*T_nap','t13*T_nap','t14*T_nap',\n",
    "    't15*T_nap','t16*T_nap','t17*T_nap','t18*T_nap','t19*T_nap','t20*T_nap'\n",
    "]\n",
    "\n",
    "# PanelOLS\n",
    "m = PanelOLS(\n",
    "    dependent=t['productivity'],\n",
    "    exog=t[X]\n",
    ").fit(cov_type='clustered', cluster_entity=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regresión a tabla\n",
    "res = pd.DataFrame({'tau':m.params.index, 'est':m.params.values, 'se':m.std_errors.values}, index=range(len(m.params)))\n",
    "res = pd.merge(pd.DataFrame({'tau':[f't{str(i)}*T_nap' for i in range(-7, 21)]}), res, on='tau', how='left')\n",
    "# res = res.fillna(0)\n",
    "\n",
    "# Graficar\n",
    "plt.errorbar(\n",
    "    x=range(-7,21), y=res['est'], yerr=res['se']*1.96,\n",
    "    capsize=3, capthick=1, ecolor='C0', marker='o',\n",
    "    markerfacecolor='C1', markeredgecolor='C1'\n",
    ")\n",
    "plt.axvline(0, ls='--', lw=1, color='C0')\n",
    "plt.axhline(0, ls='-', lw=1, color='black')\n",
    "plt.xlabel('Días desde tratamiento')\n",
    "plt.ylabel('Productividad')\n",
    "\n",
    "# Save\n",
    "try:\n",
    "    plt.savefig('../fig/f36-prod.png', dpi=200, bbox_inches='tight')\n",
    "except:\n",
    "    True\n",
    "# Show\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ATT con tiempo binario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ATT con t binario\n",
    "t = d.groupby(['T_nap','post'])['productivity'].mean().reset_index(name='prod')\n",
    "t = t.pivot(index='post', columns='T_nap', values='prod')\n",
    "\n",
    "# ATT\n",
    "att = (t.iloc[1,1] - t.iloc[0,1]) - (t.iloc[1,0] - t.iloc[0,0])\n",
    "print(f'ATT = {round(att, 2)}')\n",
    "\n",
    "# Print table\n",
    "# print(t.to_latex(label='t_prod_bin', caption='ATT sobre productividad', float_format='%.2f'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ATT through time sobre el resto de las variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for y in ['nap_time_mins','sleep_report','happy','cog','typing_time_hr']:\n",
    "    # All effects into one frame\n",
    "    s1 = pd.get_dummies(d[['t']], columns=['t'], prefix_sep='').drop('t0', axis=1)\n",
    "    s2 = s1.multiply(d['T_nap'], axis=0)\n",
    "    s2.columns = [f'{col}*T_nap' for col in s2.columns]\n",
    "    t = pd.concat([d, s1, s2.assign(const = 1)], axis=1)\n",
    "\n",
    "    # Reshape\n",
    "    t = t.set_index(['pid','t'])\n",
    "\n",
    "    # Fit model\n",
    "    m = PanelOLS(\n",
    "        dependent=t[y],\n",
    "        exog=t[X]\n",
    "    ).fit(cov_type='clustered', cluster_entity=True)\n",
    "\n",
    "    # To table\n",
    "    res = pd.DataFrame({'tau':[f't{str(i)}*T_nap' for i in range(-7, 21)]})\n",
    "    res = res.merge(\n",
    "        pd.DataFrame({'tau':m.params.index, 'est':m.params.values, 'se':m.std_errors.values}),\n",
    "        on='tau', how='left'\n",
    "    )\n",
    "\n",
    "    # Plot\n",
    "    plt.errorbar(\n",
    "        x=range(-7,21), y=res['est'], yerr=res['se']*1.96,\n",
    "        capsize=3, capthick=1, ecolor='C0', marker='o',\n",
    "        markerfacecolor='C1', markeredgecolor='C1'\n",
    "    )\n",
    "    plt.axvline(0, ls='--', lw=1, color='C0')\n",
    "    plt.axhline(0, ls='-', lw=1, color='black')\n",
    "    plt.xlabel('Días desde tratamiento')\n",
    "    plt.ylabel(y)\n",
    "\n",
    "    # Save\n",
    "    try:\n",
    "        plt.savefig(f'../fig/f36-{y}.png', dpi=200, bbox_inches='tight')\n",
    "    except:\n",
    "        True\n",
    "    # Show\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Efectos con tiempo binario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = []\n",
    "for y in ['nap_time_mins','sleep_report','happy','cog','typing_time_hr']:\n",
    "    # Datos para PanelOLS\n",
    "    t = d.assign(\n",
    "        const = 1,\n",
    "        t = d['post'],\n",
    "        T_napXpost = d['T_nap'].multiply(d['post'])\n",
    "    )\n",
    "\n",
    "    # t \n",
    "    t = t.groupby(['pid','t'])[[y,'const','T_nap','post','T_napXpost']].mean()\n",
    "    \n",
    "    # Fit\n",
    "    m = PanelOLS(\n",
    "        dependent=t[y],\n",
    "        exog=t[['const','T_nap','post','T_napXpost']]\n",
    "    ).fit(cov_type='clustered', cluster_entity=True)\n",
    "\n",
    "    # Append\n",
    "    l.append(\n",
    "        (y, m.params['T_napXpost'], m.std_errors['T_napXpost'], m.pvalues['T_napXpost'])\n",
    "    )\n",
    "\n",
    "# Results\n",
    "res = pd.DataFrame(data=l, columns=['outcome','tau','se','p'])\n",
    "res\n",
    "\n",
    "# latex\n",
    "print(res.to_latex(float_format='%.2f', caption='ATTs con tiempo binario', label='t363', index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "main.ipynb",
   "provenance": []
  },
  "interpreter": {
   "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "nbformat": 4,
  "nbformat_minor": 5
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
